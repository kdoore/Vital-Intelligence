---
description: Branching Narrative Structures Provide a Creative Learning Approach
---

# Creative Automata: ARGs, Playful Simulations:

***

### Inner Crew Starships: How We Run Simulations of Each Other

One way to understand intelligence—human or artificial—is to see each of us as a **little starship** piloted by an inner crew.

Inside the dome of the ship are four core “aliens,” matching the Jungian cognitive functions:

* **♠ Sensing** – the alien who trusts what can be touched, tasted, measured.
* **♥ Feeling** – the alien who tracks values, connection, and “is this right for us?”
* **♦ Thinking** – the alien who loves consistency, logic, and clean structures.
* **♣ Intuition** – the alien who sees patterns, possibilities, and futures that don’t exist yet.

In most people, one of these is the **pilot** (dominant function), another is the **copilot** (auxiliary), and the other two sit in the back of the ship. They’re still part of the crew—but they often get less practice, less respect, or show up in clumsy ways when stressed.

Beneath all of them is the **metacognitive console**: the part of us that can step back and notice,

> “Oh, my Thinking alien is driving at 200 km/h,\
> while my Feeling alien is curled up in the back seat.”

This is the “Observer” that can invite other crew members to help steer.

***

### We Are All Running Simulations

From the outside, we look like humans in conversation. On the inside, each starship is:

* constantly **running a simulation** of the world,
* filling in the gaps with its favorite function (pilot bias),
* and running a simulation of **what it thinks other starships are thinking.**

That simulation of “what must be going on in their head” is our **theory of mind**. It is essential for cooperation—**and deeply unreliable**.

**Our inner models are shaped by:**

* personal history and trauma,
* culture and language,
* epigenetics and nervous-system wiring,
* our age, context, and moment-by-moment physiological state.

From this perspective, we are all a little bit alien to each other. We never get direct access to someone else’s experience. We only ever interact with our **model** of them.

***

### Why Kindness Matters for Simulation-Based Creatures

When we are in survival mode—high threat, high stress—our starship shrinks. The pilot grabs the controls, slams the throttle, and locks the doors. Our simulation of the world narrows to:

* “Who is safe?”
* “Where is the threat?”
* “How do I win or escape?”

Information from the other crew members gets filtered out. Our **theory of mind** about others collapses into stereotypes, projections, or fear stories. We see less and react more.

Kindness, in this framework, is not about being “nice.” It is:

* a **commitment to treat our own simulation as partial**,
* a willingness to assume that other starships are also trying to navigate with limited sensors,
* and a choice to create enough safety that more of the crew can come online.

When we approach others with this kind of kindness, we implicitly say:

> “Your model is incomplete, and so is mine.\
> Let’s share what our starships are seeing.”

This opens the door for genuine collaboration and for **reverse mentoring**: younger starships, whose sensors are tuned to digital ecosystems and VUCA realities, can teach older starships whose experience lies in different parts of the sky.

***

### Holarchy Inside One Starship

The holarchy model doesn’t just apply to societies or AI systems; it also applies _inside_ one person.

Within a single starship we can see:

* **Sub-holons**: each cognitive function is a mini-agent with its own history and strengths.
* **Polyvagal states**: the nervous system modulates whether the whole ship is in open exploration, high alert, or shutdown.
* **Shadow ship**: mirrored, unacknowledged patterns that form when parts of the crew are exiled or overruled.

Individuation—Jung’s term for maturing into a more whole self—can be described as:

> learning to let the entire crew participate,\
> integrating the shadow ship,\
> and updating the navigation charts as new information arrives.

In a holarchic sense, a well-integrated starship is one where information flows fluidly between:

* body and mind,
* emotion and analysis,
* present facts and future possibilities.

***

#### Why This Matters for AI Literacy

AI systems are also starships of a sort: pattern engines that run simulations of text, images, futures. When humans who haven’t met their own inner crew start piloting very powerful external simulations, the risk of misalignment grows.

Trauma-informed AI literacy offers young (and not-so-young) people:

* models for understanding their **own simulations**,
* language for talking about bias, blind spots, and theory of mind,
* and playful metaphors—like inner starships—that make these ideas feel safe enough to explore.

If each student can say, with curiosity:

> “I’m an inner crew starship, navigating with partial maps.\
> So is everyone else. So is our AI.”

then the TAI-KPI project has already done something radical: it has turned fear of the unknown into a shared invitation to **co-navigate**.
