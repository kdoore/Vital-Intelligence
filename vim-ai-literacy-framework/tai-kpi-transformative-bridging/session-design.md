# Session design

_For instructors and facilitators · Layer 1_

***

## The core design principle

Every session begins inside the learner's actual information environment — not a curated case study chosen by an instructor. A learner brings any article that produced a genuine emotional response: anxiety, anger, confusion, hope, outrage, numbness. That article becomes the **event card** — the starting point for practicing all three panels together.

This design choice is not incidental. It means:

* The content is always current. It cannot go stale. It cannot be dismissed as irrelevant. It meets learners exactly where their nervous systems already are.
* And it models the framework's own premise: _events are inevitable, everywhere, ongoing._ The classroom is not separate from the information environment. It is a safe container for practicing what to do when the information environment activates you.

***

{% hint style="info" %}
### A note on polarization in the room

In any group of learners, you will have a spectrum. AI enthusiasts who dismiss concern as technophobia. People genuinely frightened about their jobs, their privacy, their children's futures. People who have been directly harmed — by scams, surveillance, algorithmic bias, or exposure to harmful content. People so deep in an information bubble that the framework itself may initially feel like propaganda.

**Do not try to correct any of these positions in the first session.**

The Gyroscope panel exists precisely because you cannot reach anyone's Radar or Compass until something first creates enough safety to think. Your job in session one is stabilization — not persuasion.

Humor is your most powerful tool here. It is physiologically impossible to remain rigidly defended against an idea that makes you laugh. Use it generously, and use it to illuminate rather than dismiss.
{% endhint %}

***

## Four-Session Arc

{% stepper %}
{% step %}
### Session 1 — I feel anxious about AI

Primary panel: Gyroscope

Open with the entry question: _what happened the last time an AI told you something that felt wrong?_ Let people share briefly — two minutes each, no crosstalk. The goal is simply to establish that everyone in the room has had this experience. Normalizing the event is the first co-regulation move.

Introduce the concept of nervous system state as the prerequisite for interpretation. You can do this lightly — you don't need to teach neuroscience. A simple framing: _when we're flooded or shut down, we become unreliable interpreters. This isn't weakness. It's biology. And it's the first thing we need to address._

Introduce articles about AI anxiety — either ones you've brought as examples or ones learners have brought. Use humor. The goal is to demonstrate that you can look at frightening material together without catastrophizing or dismissing.

Close with a simple Gyroscope practice: name one person in your life you trust enough to think out loud with about AI. That's your co-regulation anchor.

Sample articles to have ready:

* Any article about AI deepfakes in elections
* Any article about AI replacing jobs in a specific industry relevant to the group
* Any article about AI surveillance in schools or workplaces
* Any article about AI-generated scams targeting older adults

Choose ones that are slightly absurd as well as genuinely concerning — absurdity opens the humor channel.
{% endstep %}

{% step %}
### Session 2 — I don't know what's true anymore

Primary panel: Radar

Open by asking: _has anyone tried to fact-check an AI output this week? What happened?_

This session introduces the most counterintuitive idea in the framework: **AI systems don't just occasionally produce misinformation. At scale, it is mathematically inevitable.** This reframe — from "AI is broken when it hallucinates" to "AI hallucinates as a feature of how stochastic systems work" — is genuinely liberating for many learners. It means the problem isn't their failure to use the tool correctly. It means verification is always part of the job.

Use an article about a specific AI hallucination or deepfake event. Walk through the Radar questions together as a group: Where did this information come from? Who benefits from us believing it? What do we genuinely not know yet? Who is paying a cost that isn't visible in this picture?

Introduce the concept of **measuring your doubt** rather than eliminating it. You don't need to reach certainty. You need to know approximately how uncertain you are, and act proportionally.

Close with a small practice: before the next session, notice once when you feel certain about something you read — and ask the Radar questions about it.
{% endstep %}

{% step %}
### Session 3 — I don't know what to do

Primary panel: Compass

This session addresses the paralysis that often follows genuine understanding of AI's complexity and risks. Once you see the externalities, the labor harm, the ecological costs, the epistemic erosion — it can feel overwhelming. The Compass panel is the antidote to paralysis.

Open with the evolutionary framing: _altruistic groups outperform selfish groups at scale._ This is not a moral argument — it is an empirical one, grounded in multilevel selection theory. Kindness and collaboration are not sentimental ideals. They are the thermodynamically viable path for collective adaptation.

Use an article about AI governance, labor organizing around AI, or community-owned data initiatives. These are harder to find than anxiety articles, which is itself a Radar observation worth naming.

Walk through the Compass questions: What assumption am I most attached to right now? What's the smallest action I could take to test whether I'm right? What would honest and kind look like here, even if it's uncomfortable?

Introduce the concept of **small intentional acts of alignment** as the mechanism of change. Fractal systems are sensitive to initial conditions. Small resonant actions can cascade. You do not need to solve AI governance to act wisely today.
{% endstep %}

{% step %}
### Session 4 — What can I actually do from here?

Integration and card deck practice

This session uses the full card deck for the first time in its complete form. Learners bring their own articles — events from their actual information environment this week — and work through them in small groups using the cards as scaffolding.

The session closes with each learner naming one commitment — not a resolution, not a life change. One small, specific, verifiable act of collaborative stewardship they will take before the next time they encounter an AI-mediated event.

And then the next event arrives. And the cycle begins again.
{% endstep %}
{% endstepper %}

***

{% hint style="info" %}
### A note on older adult learners

Older adults bring something that younger learners often lack: extensive lived experience with VUCA conditions. Economic disruptions. Health crises. Institutional failures. Social upheaval. They have already been developing Gyroscope, Radar, and Compass capacities for decades — they just don't have those names for them.

For this audience, the frame shifts slightly. Rather than teaching new skills, you are **naming capacities they already have and extending them into a new domain.** That reframe matters enormously for engagement and dignity.

The article exercise works especially well with older learners because they typically have strong opinions about information quality, having lived through multiple media transformations. Use that.
{% endhint %}

***

{% hint style="info" %}
### On humor as pedagogy

The most effective moments in this framework are often the ones that make people laugh at something they were previously only able to be anxious about. This is not about making light of real harms. It is about demonstrating that you can hold a genuinely frightening reality with enough equanimity to think clearly about it.

_The Emperor's New Clothes_ is a useful reference here. The child who names what everyone else can see but won't say is performing a Radar function under social pressure. That story is thousands of years old. The same dynamic plays out every day in organizational responses to AI outputs.

When in doubt, ask: _what would this look like if it were a fairy tale?_ That question often unlocks more insight than any analytical framework.
{% endhint %}
